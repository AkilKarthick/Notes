Stream API:

    Stream is a pipeline to process data from a collection
    used to process collections in a functional style using lambda expression
    it allow paraller processing tooand supports different data processing operations.

    stream do not store data but process data frm collection,arrays etc
    it enables chaining operation like (filetring,mapping sorting)

    stream can be sequential or paralle for concurrency
    operation are either intermediate or terminal

we have 
    Source - list?set?array
    intermediate operations - filter map
    Terminal opertaion - reduce, collectr, forEach
-----------------------------------------

List<String> l1 = Arrays.asList("lk","a");

    1.//from collection
    Stream<String> stream1 = l1.stream();
    
    2.//from array
    String[] A = {"a","b"}

Stream<string> stream2 = Arrays.stream(A);

3.//from values

    Stream<Ineger> stream3 = Stream.of(1,2,3,45);
    Stream<String> st = stream.of("ak","ka");

4.//building a stream from files is also possible

    String fileName = "c:/empl.txt";
    try(Stream<String> s = Files.lines(Path.get(fileName))) {
    catch(IoException e){ e.printStackTrace();
    Stream<Integer> stream4 = Stream.iterate(1, n->n+1).limit(5);
    stream4.forEach(System.out::println);

-----------------------
Intermediate Operations (lazy, return streams):
------------------------
JUST RETURN ANOTHER STREAM.
Intermediate operations build the processing pipeline and return a new Stream for further processing. They are lazy, so no actual processing happens until a terminal operation is called.

shortcut: fmsdls

filter(): Filter elements
map(): Transform elements
sorted(): Sort elements
distinct(): Remove duplicates
limit(): Limit size
skip(): Skip first n elements

-------------------
Terminal Operations (trigger processing, return result):
---------------------
    Terminal operations are the last in the pipeline 
    trigger the execution of all accumulated intermediate operations to produce a final result

shortcut: fcrcaf

forEach(): Consume elements
collect(): Accumulate results (toList, toSet)
reduce(): Combine elements into one  eg: doing sum of all elements 
count(): Number of elements
anyMatch(), allMatch(), noneMatch(): Predicate checks
findFirst(), findAny(): Optional first/any match

=================
Parallel Streams:
==================

    parallelStream() to enable parallel processing
    Efficient utilization of multiple CPU cores for big data

List<String> names = Arrays.asList("John", "Jane", "Mark", "Diana");

        List<String> result = names.stream()
            .filter(name -> name.startsWith("J"))
            .map(String::toUpperCase)
            .sorted()
            .limit(2)
            .collect(Collectors.toList());
        
        System.out.println(result);  // Output: [JANE, JOHN]

What is the difference between map() and flatMap()?

    map() - transform each elemet to exactly  one elememtn
    flatmap()- flattens nested streams into single stream
                flatMap then merges these individual streams into one stream of integers

How does parallel stream work?

    Parallel streams use multiple threads from a ForkJoinPool to process data concurrently        for better performance on large datasets.

What are short-circuiting operations?

Operations like anyMatch(), allMatch(), noneMatch(), findFirst(), and findAny() which may stop processing early.




